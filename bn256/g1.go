// Copyright 2020 ConsenSys Software Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by gurvy DO NOT EDIT

package bn256

import (
	"encoding/binary"
	"errors"
	"io"
	"math"
	"math/big"
	"runtime"
	"sync"

	"github.com/consensys/gurvy/bn256/fp"
	"github.com/consensys/gurvy/bn256/fr"
	"github.com/consensys/gurvy/utils"
	"github.com/consensys/gurvy/utils/parallel"
)

// G1Affine point in affine coordinates
type G1Affine struct {
	X, Y fp.Element
}

// G1Jac is a point with fp.Element coordinates
type G1Jac struct {
	X, Y, Z fp.Element
}

//  g1JacExtended parameterized jacobian coordinates (x=X/ZZ, y=Y/ZZZ, ZZ**3=ZZZ**2)
type g1JacExtended struct {
	X, Y, ZZ, ZZZ fp.Element
}

// g1Proj point in projective coordinates
type g1Proj struct {
	x, y, z fp.Element
}

// -------------------------------------------------------------------------------------------------
// Affine

// ScalarMultiplication computes and returns p = a*s
func (p *G1Affine) ScalarMultiplication(a *G1Affine, s *big.Int) *G1Affine {
	var _p G1Jac
	_p.FromAffine(a)
	_p.mulGLV(&_p, s)
	p.FromJacobian(&_p)
	return p
}

// Equal tests if two points (in Affine coordinates) are equal
func (p *G1Affine) Equal(a *G1Affine) bool {
	return p.X.Equal(&a.X) && p.Y.Equal(&a.Y)
}

// Neg computes -G
func (p *G1Affine) Neg(a *G1Affine) *G1Affine {
	p.X = a.X
	p.Y.Neg(&a.Y)
	return p
}

// FromJacobian rescale a point in Jacobian coord in z=1 plane
func (p *G1Affine) FromJacobian(p1 *G1Jac) *G1Affine {

	var a, b fp.Element

	if p1.Z.IsZero() {
		p.X.SetZero()
		p.Y.SetZero()
		return p
	}

	a.Inverse(&p1.Z)
	b.Square(&a)
	p.X.Mul(&p1.X, &b)
	p.Y.Mul(&p1.Y, &b).Mul(&p.Y, &a)

	return p
}

func (p *G1Affine) String() string {
	var x, y fp.Element
	x.Set(&p.X)
	y.Set(&p.Y)
	return "E([" + x.String() + "," + y.String() + "]),"
}

// IsInfinity checks if the point is infinity (in affine, it's encoded as (0,0))
func (p *G1Affine) IsInfinity() bool {
	return p.X.IsZero() && p.Y.IsZero()
}

// IsOnCurve returns true if p in on the curve
func (p *G1Affine) IsOnCurve() bool {
	var point G1Jac
	point.FromAffine(p)
	return point.IsOnCurve() // call this function to handle infinity point
}

// IsInSubGroup returns true if p is in the correct subgroup, false otherwise
func (p *G1Affine) IsInSubGroup() bool {
	var _p G1Jac
	_p.FromAffine(p)
	return _p.IsOnCurve() && _p.IsInSubGroup()
}

// -------------------------------------------------------------------------------------------------
// Jacobian

// Set set p to the provided point
func (p *G1Jac) Set(a *G1Jac) *G1Jac {
	p.X, p.Y, p.Z = a.X, a.Y, a.Z
	return p
}

// Equal tests if two points (in Jacobian coordinates) are equal
func (p *G1Jac) Equal(a *G1Jac) bool {

	if p.Z.IsZero() && a.Z.IsZero() {
		return true
	}
	_p := G1Affine{}
	_p.FromJacobian(p)

	_a := G1Affine{}
	_a.FromJacobian(a)

	return _p.X.Equal(&_a.X) && _p.Y.Equal(&_a.Y)
}

// Neg computes -G
func (p *G1Jac) Neg(a *G1Jac) *G1Jac {
	*p = *a
	p.Y.Neg(&a.Y)
	return p
}

// SubAssign substracts two points on the curve
func (p *G1Jac) SubAssign(a *G1Jac) *G1Jac {
	var tmp G1Jac
	tmp.Set(a)
	tmp.Y.Neg(&tmp.Y)
	p.AddAssign(&tmp)
	return p
}

// AddAssign point addition in montgomery form
// https://hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-3.html#addition-add-2007-bl
func (p *G1Jac) AddAssign(a *G1Jac) *G1Jac {

	// p is infinity, return a
	if p.Z.IsZero() {
		p.Set(a)
		return p
	}

	// a is infinity, return p
	if a.Z.IsZero() {
		return p
	}

	var Z1Z1, Z2Z2, U1, U2, S1, S2, H, I, J, r, V fp.Element
	Z1Z1.Square(&a.Z)
	Z2Z2.Square(&p.Z)
	U1.Mul(&a.X, &Z2Z2)
	U2.Mul(&p.X, &Z1Z1)
	S1.Mul(&a.Y, &p.Z).
		Mul(&S1, &Z2Z2)
	S2.Mul(&p.Y, &a.Z).
		Mul(&S2, &Z1Z1)

	// if p == a, we double instead
	if U1.Equal(&U2) && S1.Equal(&S2) {
		return p.DoubleAssign()
	}

	H.Sub(&U2, &U1)
	I.Double(&H).
		Square(&I)
	J.Mul(&H, &I)
	r.Sub(&S2, &S1).Double(&r)
	V.Mul(&U1, &I)
	p.X.Square(&r).
		Sub(&p.X, &J).
		Sub(&p.X, &V).
		Sub(&p.X, &V)
	p.Y.Sub(&V, &p.X).
		Mul(&p.Y, &r)
	S1.Mul(&S1, &J).Double(&S1)
	p.Y.Sub(&p.Y, &S1)
	p.Z.Add(&p.Z, &a.Z)
	p.Z.Square(&p.Z).
		Sub(&p.Z, &Z1Z1).
		Sub(&p.Z, &Z2Z2).
		Mul(&p.Z, &H)

	return p
}

// AddMixed point addition
// http://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#addition-madd-2007-bl
func (p *G1Jac) AddMixed(a *G1Affine) *G1Jac {

	//if a is infinity return p
	if a.X.IsZero() && a.Y.IsZero() {
		return p
	}
	// p is infinity, return a
	if p.Z.IsZero() {
		p.X = a.X
		p.Y = a.Y
		p.Z.SetOne()
		return p
	}

	// get some Element from our pool
	var Z1Z1, U2, S2, H, HH, I, J, r, V fp.Element
	Z1Z1.Square(&p.Z)
	U2.Mul(&a.X, &Z1Z1)
	S2.Mul(&a.Y, &p.Z).
		Mul(&S2, &Z1Z1)

	// if p == a, we double instead
	if U2.Equal(&p.X) && S2.Equal(&p.Y) {
		return p.DoubleAssign()
	}

	H.Sub(&U2, &p.X)
	HH.Square(&H)
	I.Double(&HH).Double(&I)
	J.Mul(&H, &I)
	r.Sub(&S2, &p.Y).Double(&r)
	V.Mul(&p.X, &I)
	p.X.Square(&r).
		Sub(&p.X, &J).
		Sub(&p.X, &V).
		Sub(&p.X, &V)
	J.Mul(&J, &p.Y).Double(&J)
	p.Y.Sub(&V, &p.X).
		Mul(&p.Y, &r)
	p.Y.Sub(&p.Y, &J)
	p.Z.Add(&p.Z, &H)
	p.Z.Square(&p.Z).
		Sub(&p.Z, &Z1Z1).
		Sub(&p.Z, &HH)

	return p
}

// Double doubles a point in Jacobian coordinates
// https://hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-3.html#doubling-dbl-2007-bl
func (p *G1Jac) Double(q *G1Jac) *G1Jac {
	p.Set(q)
	p.DoubleAssign()
	return p
}

// DoubleAssign doubles a point in Jacobian coordinates
// https://hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-3.html#doubling-dbl-2007-bl
func (p *G1Jac) DoubleAssign() *G1Jac {

	// get some Element from our pool
	var XX, YY, YYYY, ZZ, S, M, T fp.Element

	XX.Square(&p.X)
	YY.Square(&p.Y)
	YYYY.Square(&YY)
	ZZ.Square(&p.Z)
	S.Add(&p.X, &YY)
	S.Square(&S).
		Sub(&S, &XX).
		Sub(&S, &YYYY).
		Double(&S)
	M.Double(&XX).Add(&M, &XX)
	p.Z.Add(&p.Z, &p.Y).
		Square(&p.Z).
		Sub(&p.Z, &YY).
		Sub(&p.Z, &ZZ)
	T.Square(&M)
	p.X = T
	T.Double(&S)
	p.X.Sub(&p.X, &T)
	p.Y.Sub(&S, &p.X).
		Mul(&p.Y, &M)
	YYYY.Double(&YYYY).Double(&YYYY).Double(&YYYY)
	p.Y.Sub(&p.Y, &YYYY)

	return p
}

// ScalarMultiplication computes and returns p = a*s
// see https://www.iacr.org/archive/crypto2001/21390189.pdf
func (p *G1Jac) ScalarMultiplication(a *G1Jac, s *big.Int) *G1Jac {
	return p.mulGLV(a, s)
}

func (p *G1Jac) String() string {
	if p.Z.IsZero() {
		return "O"
	}
	_p := G1Affine{}
	_p.FromJacobian(p)
	return "E([" + _p.X.String() + "," + _p.Y.String() + "]),"
}

// FromAffine sets p = Q, p in Jacboian, Q in affine
func (p *G1Jac) FromAffine(Q *G1Affine) *G1Jac {
	if Q.X.IsZero() && Q.Y.IsZero() {
		p.Z.SetZero()
		p.X.SetOne()
		p.Y.SetOne()
		return p
	}
	p.Z.SetOne()
	p.X.Set(&Q.X)
	p.Y.Set(&Q.Y)
	return p
}

// IsOnCurve returns true if p in on the curve
func (p *G1Jac) IsOnCurve() bool {
	var left, right, tmp fp.Element
	left.Square(&p.Y)
	right.Square(&p.X).Mul(&right, &p.X)
	tmp.Square(&p.Z).
		Square(&tmp).
		Mul(&tmp, &p.Z).
		Mul(&tmp, &p.Z).
		Mul(&tmp, &bCurveCoeff)
	right.Add(&right, &tmp)
	return left.Equal(&right)
}

// IsInSubGroup returns true if p is on the r-torsion, false otherwise.
// For bn curves, the r-torsion in E(Fp) is the full group, so we just check that
// the point is on the curve.
func (p *G1Jac) IsInSubGroup() bool {

	return p.IsOnCurve()

}

// mulWindowed 2-bits windowed exponentiation
func (p *G1Jac) mulWindowed(a *G1Jac, s *big.Int) *G1Jac {

	var res G1Jac
	var ops [3]G1Jac

	res.Set(&g1Infinity)
	ops[0].Set(a)
	ops[1].Double(&ops[0])
	ops[2].Set(&ops[0]).AddAssign(&ops[1])

	b := s.Bytes()
	for i := range b {
		w := b[i]
		mask := byte(0xc0)
		for j := 0; j < 4; j++ {
			res.DoubleAssign().DoubleAssign()
			c := (w & mask) >> (6 - 2*j)
			if c != 0 {
				res.AddAssign(&ops[c-1])
			}
			mask = mask >> 2
		}
	}
	p.Set(&res)

	return p

}

// phi assigns p to phi(a) where phi: (x,y)->(ux,y), and returns p
func (p *G1Jac) phi(a *G1Jac) *G1Jac {
	p.Set(a)

	p.X.Mul(&p.X, &thirdRootOneG1)

	return p
}

// mulGLV performs scalar multiplication using GLV
// see https://www.iacr.org/archive/crypto2001/21390189.pdf
func (p *G1Jac) mulGLV(a *G1Jac, s *big.Int) *G1Jac {

	var table [15]G1Jac
	var zero big.Int
	var res G1Jac
	var k1, k2 fr.Element

	res.Set(&g1Infinity)

	// table[b3b2b1b0-1] = b3b2*phi(a) + b1b0*a
	table[0].Set(a)
	table[3].phi(a)

	// split the scalar, modifies +-a, phi(a) accordingly
	k := utils.SplitScalar(s, &glvBasis)

	if k[0].Cmp(&zero) == -1 {
		k[0].Neg(&k[0])
		table[0].Neg(&table[0])
	}
	if k[1].Cmp(&zero) == -1 {
		k[1].Neg(&k[1])
		table[3].Neg(&table[3])
	}

	// precompute table (2 bits sliding window)
	// table[b3b2b1b0-1] = b3b2*phi(a) + b1b0*a if b3b2b1b0 != 0
	table[1].Double(&table[0])
	table[2].Set(&table[1]).AddAssign(&table[0])
	table[4].Set(&table[3]).AddAssign(&table[0])
	table[5].Set(&table[3]).AddAssign(&table[1])
	table[6].Set(&table[3]).AddAssign(&table[2])
	table[7].Double(&table[3])
	table[8].Set(&table[7]).AddAssign(&table[0])
	table[9].Set(&table[7]).AddAssign(&table[1])
	table[10].Set(&table[7]).AddAssign(&table[2])
	table[11].Set(&table[7]).AddAssign(&table[3])
	table[12].Set(&table[11]).AddAssign(&table[0])
	table[13].Set(&table[11]).AddAssign(&table[1])
	table[14].Set(&table[11]).AddAssign(&table[2])

	// bounds on the lattice base vectors guarantee that k1, k2 are len(r)/2 bits long max
	k1.SetBigInt(&k[0]).FromMont()
	k2.SetBigInt(&k[1]).FromMont()

	// loop starts from len(k1)/2 due to the bounds
	for i := len(k1)/2 - 1; i >= 0; i-- {
		mask := uint64(3) << 62
		for j := 0; j < 32; j++ {
			res.Double(&res).Double(&res)
			b1 := (k1[i] & mask) >> (62 - 2*j)
			b2 := (k2[i] & mask) >> (62 - 2*j)
			if b1|b2 != 0 {
				s := (b2<<2 | b1)
				res.AddAssign(&table[s-1])
			}
			mask = mask >> 2
		}
	}

	p.Set(&res)
	return p
}

// MultiExp implements section 4 of https://eprint.iacr.org/2012/549.pdf
// optionally, takes as parameter a CPUSemaphore struct
// enabling to set max number of cpus to use
func (p *G1Affine) MultiExp(points []G1Affine, scalars []fr.Element, opts ...*CPUSemaphore) *G1Affine {
	var _p G1Jac
	_p.MultiExp(points, scalars, opts...)
	p.FromJacobian(&_p)
	return p
}

// MultiExp implements section 4 of https://eprint.iacr.org/2012/549.pdf
// optionally, takes as parameter a CPUSemaphore struct
// enabling to set max number of cpus to use
func (p *G1Jac) MultiExp(points []G1Affine, scalars []fr.Element, opts ...*CPUSemaphore) *G1Jac {
	// note:
	// each of the msmCX method is the same, except for the c constant it declares
	// duplicating (through template generation) these methods allows to declare the buckets on the stack
	// the choice of c needs to be improved:
	// there is a theoritical value that gives optimal asymptotics
	// but in practice, other factors come into play, including:
	// * if c doesn't divide 64, the word size, then we're bound to select bits over 2 words of our scalars, instead of 1
	// * number of CPUs
	// * cache friendliness (which depends on the host, G1 or G2... )
	//	--> for example, on BN256, a G1 point fits into one cache line of 64bytes, but a G2 point don't.

	// for each msmCX
	// step 1
	// we compute, for each scalars over c-bit wide windows, nbChunk digits
	// if the digit is larger than 2^{c-1}, then, we borrow 2^c from the next window and substract
	// 2^{c} to the current digit, making it negative.
	// negative digits will be processed in the next step as adding -G into the bucket instead of G
	// (computing -G is cheap, and this saves us half of the buckets)
	// step 2
	// buckets are declared on the stack
	// notice that we have 2^{c-1} buckets instead of 2^{c} (see step1)
	// we use jacobian extended formulas here as they are faster than mixed addition
	// msmProcessChunk places points into buckets base on their selector and return the weighted bucket sum in given channel
	// step 3
	// reduce the buckets weigthed sums into our result (msmReduceChunk)

	var opt *CPUSemaphore
	if len(opts) > 0 {
		opt = opts[0]
	} else {
		opt = NewCPUSemaphore(runtime.NumCPU())
	}

	var C uint64
	nbPoints := len(points)

	// implemented msmC methods (the c we use must be in this slice)
	implementedCs := []uint64{4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 21}

	// approximate cost (in group operations)
	// cost = bits/c * (nbPoints + 2^{c})
	// this needs to be verified empirically.
	// for example, on a MBP 2016, for G2 MultiExp > 8M points, hand picking c gives better results
	min := math.MaxFloat64
	for _, c := range implementedCs {
		cc := fr.Limbs * 64 * (nbPoints + (1 << (c)))
		cost := float64(cc) / float64(c)
		if cost < min {
			min = cost
			C = c
		}
	}

	// empirical, needs to be tuned.

	// if C > 16 && nbPoints < 1 << 23 {
	// 	C = 16
	// }

	// take all the cpus to ourselves
	opt.lock.Lock()

	// partition the scalars
	// note: we do that before the actual chunk processing, as for each c-bit window (starting from LSW)
	// if it's larger than 2^{c-1}, we have a carry we need to propagate up to the higher window
	scalars = partitionScalars(scalars, C)

	switch C {

	case 4:
		return p.msmC4(points, scalars, opt)

	case 5:
		return p.msmC5(points, scalars, opt)

	case 6:
		return p.msmC6(points, scalars, opt)

	case 7:
		return p.msmC7(points, scalars, opt)

	case 8:
		return p.msmC8(points, scalars, opt)

	case 9:
		return p.msmC9(points, scalars, opt)

	case 10:
		return p.msmC10(points, scalars, opt)

	case 11:
		return p.msmC11(points, scalars, opt)

	case 12:
		return p.msmC12(points, scalars, opt)

	case 13:
		return p.msmC13(points, scalars, opt)

	case 14:
		return p.msmC14(points, scalars, opt)

	case 15:
		return p.msmC15(points, scalars, opt)

	case 16:
		return p.msmC16(points, scalars, opt)

	case 20:
		return p.msmC20(points, scalars, opt)

	case 21:
		return p.msmC21(points, scalars, opt)

	case 22:
		return p.msmC22(points, scalars, opt)

	default:
		panic("unimplemented")
	}
}

// msmReduceChunkG1Affine reduces the weighted sum of the buckets into the result of the multiExp
func msmReduceChunkG1Affine(p *G1Jac, c int, chChunks []chan G1Jac) *G1Jac {
	totalj := <-chChunks[len(chChunks)-1]
	p.Set(&totalj)
	for j := len(chChunks) - 2; j >= 0; j-- {
		for l := 0; l < c; l++ {
			p.DoubleAssign()
		}
		totalj := <-chChunks[j]
		p.AddAssign(&totalj)
	}
	return p
}

func msmProcessChunkG1Affine(chunk uint64,
	chRes chan<- G1Jac,
	buckets []g1JacExtended,
	c uint64,
	points []G1Affine,
	scalars []fr.Element) {

	mask := uint64((1 << c) - 1) // low c bits are 1
	msbWindow := uint64(1 << (c - 1))

	for i := 0; i < len(buckets); i++ {
		buckets[i].setInfinity()
	}

	jc := uint64(chunk * c)
	s := selector{}
	s.index = jc / 64
	s.shift = jc - (s.index * 64)
	s.mask = mask << s.shift
	s.multiWordSelect = (64%c) != 0 && s.shift > (64-c) && s.index < (fr.Limbs-1)
	if s.multiWordSelect {
		nbBitsHigh := s.shift - uint64(64-c)
		s.maskHigh = (1 << nbBitsHigh) - 1
		s.shiftHigh = (c - nbBitsHigh)
	}

	// for each scalars, get the digit corresponding to the chunk we're processing.
	for i := 0; i < len(scalars); i++ {
		bits := (scalars[i][s.index] & s.mask) >> s.shift
		if s.multiWordSelect {
			bits += (scalars[i][s.index+1] & s.maskHigh) << s.shiftHigh
		}

		if bits == 0 {
			continue
		}

		// if msbWindow bit is set, we need to substract
		if bits&msbWindow == 0 {
			// add
			buckets[bits-1].add(&points[i])
		} else {
			// sub
			buckets[bits & ^msbWindow].sub(&points[i])
		}
	}

	// reduce buckets into total
	// total =  bucket[0] + 2*bucket[1] + 3*bucket[2] ... + n*bucket[n-1]

	var runningSum, tj, total G1Jac
	runningSum.Set(&g1Infinity)
	total.Set(&g1Infinity)
	for k := len(buckets) - 1; k >= 0; k-- {
		if !buckets[k].ZZ.IsZero() {
			runningSum.AddAssign(tj.unsafeFromJacExtended(&buckets[k]))
		}
		total.AddAssign(&runningSum)
	}

	chRes <- total
	close(chRes)
}

func (p *G1Jac) msmC4(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 4                          // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	for chunk := nbChunks - 1; chunk >= 0; chunk-- {
		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC5(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 5                              // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC6(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 6                              // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC7(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 7                              // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC8(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 8                          // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	for chunk := nbChunks - 1; chunk >= 0; chunk-- {
		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC9(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 9                              // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC10(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 10                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC11(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 11                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC12(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 12                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC13(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 13                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC14(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 14                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC15(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 15                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC16(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 16                         // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	for chunk := nbChunks - 1; chunk >= 0; chunk-- {
		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC20(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 20                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC21(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 21                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

func (p *G1Jac) msmC22(points []G1Affine, scalars []fr.Element, opt *CPUSemaphore) *G1Jac {
	const c = 22                             // scalars partitioned into c-bit radixes
	const nbChunks = (fr.Limbs * 64 / c) + 1 // number of c-bit radixes in a scalar

	// for each chunk, spawn a go routine that'll loop through all the scalars
	var chChunks [nbChunks]chan G1Jac

	// wait group to wait for all the go routines to start
	var wg sync.WaitGroup
	// c doesn't divide 256, last window is smaller we can allocate less buckets
	const lastC = (fr.Limbs * 64) - (c * (fr.Limbs * 64 / c))
	chChunks[nbChunks-1] = make(chan G1Jac, 1)
	<-opt.chCpus // wait to have a cpu before scheduling
	wg.Add(1)
	go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
		wg.Done()
		var buckets [1 << (lastC - 1)]g1JacExtended
		msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
		opt.chCpus <- struct{}{} // release token in the semaphore
	}(uint64(nbChunks-1), chChunks[nbChunks-1], points, scalars)

	for chunk := nbChunks - 2; chunk >= 0; chunk-- {

		chChunks[chunk] = make(chan G1Jac, 1)
		<-opt.chCpus // wait to have a cpu before scheduling
		wg.Add(1)
		go func(j uint64, chRes chan G1Jac, points []G1Affine, scalars []fr.Element) {
			wg.Done()
			var buckets [1 << (c - 1)]g1JacExtended
			msmProcessChunkG1Affine(j, chRes, buckets[:], c, points, scalars)
			opt.chCpus <- struct{}{} // release token in the semaphore
		}(uint64(chunk), chChunks[chunk], points, scalars)
	}

	// wait for all goRoutines to actually start
	wg.Wait()

	// all my tasks are scheduled, I can let other func use avaiable tokens in the semaphore
	opt.lock.Unlock()
	return msmReduceChunkG1Affine(p, c, chChunks[:])
}

// -------------------------------------------------------------------------------------------------
// Jacobian extended

// setInfinity sets p to O
func (p *g1JacExtended) setInfinity() *g1JacExtended {
	p.X.SetOne()
	p.Y.SetOne()
	p.ZZ = fp.Element{}
	p.ZZZ = fp.Element{}
	return p
}

// fromJacExtended sets Q in affine coords
func (p *G1Affine) fromJacExtended(Q *g1JacExtended) *G1Affine {
	if Q.ZZ.IsZero() {
		p.X = fp.Element{}
		p.Y = fp.Element{}
		return p
	}
	p.X.Inverse(&Q.ZZ).Mul(&p.X, &Q.X)
	p.Y.Inverse(&Q.ZZZ).Mul(&p.Y, &Q.Y)
	return p
}

// fromJacExtended sets Q in Jacobian coords
func (p *G1Jac) fromJacExtended(Q *g1JacExtended) *G1Jac {
	if Q.ZZ.IsZero() {
		p.Set(&g1Infinity)
		return p
	}
	p.X.Mul(&Q.ZZ, &Q.X).Mul(&p.X, &Q.ZZ)
	p.Y.Mul(&Q.ZZZ, &Q.Y).Mul(&p.Y, &Q.ZZZ)
	p.Z.Set(&Q.ZZZ)
	return p
}

// unsafeFromJacExtended sets p in jacobian coords, but don't check for infinity
func (p *G1Jac) unsafeFromJacExtended(Q *g1JacExtended) *G1Jac {
	p.X.Square(&Q.ZZ).Mul(&p.X, &Q.X)
	p.Y.Square(&Q.ZZZ).Mul(&p.Y, &Q.Y)
	p.Z = Q.ZZZ
	return p
}

// sub same as add, but will negate a.Y
// http://www.hyperelliptic.org/EFD/ g1p/auto-shortw-xyzz.html#addition-madd-2008-s
func (p *g1JacExtended) sub(a *G1Affine) *g1JacExtended {

	//if a is infinity return p
	if a.X.IsZero() && a.Y.IsZero() {
		return p
	}
	// p is infinity, return a
	if p.ZZ.IsZero() {
		p.X = a.X
		p.Y = a.Y

		p.Y.Neg(&p.Y)

		p.ZZ.SetOne()
		p.ZZZ.SetOne()
		return p
	}

	var P, R fp.Element

	// p2: a, p1: p
	P.Mul(&a.X, &p.ZZ)
	P.Sub(&P, &p.X)

	R.Mul(&a.Y, &p.ZZZ)

	R.Neg(&R)

	R.Sub(&R, &p.Y)

	if P.IsZero() {
		if R.IsZero() {

			return p.doubleNeg(a)

		}
		p.ZZ = fp.Element{}
		p.ZZZ = fp.Element{}
		return p
	}

	var PP, PPP, Q, Q2, RR, X3, Y3 fp.Element

	PP.Square(&P)
	PPP.Mul(&P, &PP)
	Q.Mul(&p.X, &PP)
	RR.Square(&R)
	X3.Sub(&RR, &PPP)
	Q2.Double(&Q)
	p.X.Sub(&X3, &Q2)
	Y3.Sub(&Q, &p.X).Mul(&Y3, &R)
	R.Mul(&p.Y, &PPP)
	p.Y.Sub(&Y3, &R)
	p.ZZ.Mul(&p.ZZ, &PP)
	p.ZZZ.Mul(&p.ZZZ, &PPP)

	return p

}

// add
// http://www.hyperelliptic.org/EFD/ g1p/auto-shortw-xyzz.html#addition-madd-2008-s
func (p *g1JacExtended) add(a *G1Affine) *g1JacExtended {

	//if a is infinity return p
	if a.X.IsZero() && a.Y.IsZero() {
		return p
	}
	// p is infinity, return a
	if p.ZZ.IsZero() {
		p.X = a.X
		p.Y = a.Y

		p.ZZ.SetOne()
		p.ZZZ.SetOne()
		return p
	}

	var P, R fp.Element

	// p2: a, p1: p
	P.Mul(&a.X, &p.ZZ)
	P.Sub(&P, &p.X)

	R.Mul(&a.Y, &p.ZZZ)

	R.Sub(&R, &p.Y)

	if P.IsZero() {
		if R.IsZero() {

			return p.double(a)

		}
		p.ZZ = fp.Element{}
		p.ZZZ = fp.Element{}
		return p
	}

	var PP, PPP, Q, Q2, RR, X3, Y3 fp.Element

	PP.Square(&P)
	PPP.Mul(&P, &PP)
	Q.Mul(&p.X, &PP)
	RR.Square(&R)
	X3.Sub(&RR, &PPP)
	Q2.Double(&Q)
	p.X.Sub(&X3, &Q2)
	Y3.Sub(&Q, &p.X).Mul(&Y3, &R)
	R.Mul(&p.Y, &PPP)
	p.Y.Sub(&Y3, &R)
	p.ZZ.Mul(&p.ZZ, &PP)
	p.ZZZ.Mul(&p.ZZZ, &PPP)

	return p

}

// doubleNeg same as double, but will negate q.Y
func (p *g1JacExtended) doubleNeg(q *G1Affine) *g1JacExtended {

	var U, S, M, _M, Y3 fp.Element

	U.Double(&q.Y)

	U.Neg(&U)

	p.ZZ.Square(&U)
	p.ZZZ.Mul(&U, &p.ZZ)
	S.Mul(&q.X, &p.ZZ)
	_M.Square(&q.X)
	M.Double(&_M).
		Add(&M, &_M) // -> + a, but a=0 here
	p.X.Square(&M).
		Sub(&p.X, &S).
		Sub(&p.X, &S)
	Y3.Sub(&S, &p.X).Mul(&Y3, &M)
	U.Mul(&p.ZZZ, &q.Y)

	p.Y.Add(&Y3, &U)

	return p

}

// double point in ZZ coords
// http://www.hyperelliptic.org/EFD/ g1p/auto-shortw-xyzz.html#doubling-dbl-2008-s-1
func (p *g1JacExtended) double(q *G1Affine) *g1JacExtended {

	var U, S, M, _M, Y3 fp.Element

	U.Double(&q.Y)

	p.ZZ.Square(&U)
	p.ZZZ.Mul(&U, &p.ZZ)
	S.Mul(&q.X, &p.ZZ)
	_M.Square(&q.X)
	M.Double(&_M).
		Add(&M, &_M) // -> + a, but a=0 here
	p.X.Square(&M).
		Sub(&p.X, &S).
		Sub(&p.X, &S)
	Y3.Sub(&S, &p.X).Mul(&Y3, &M)
	U.Mul(&p.ZZZ, &q.Y)

	p.Y.Sub(&Y3, &U)

	return p

}

// -------------------------------------------------------------------------------------------------
// Projective

// FromJacobian converts a point from Jacobian to projective coordinates
func (p *g1Proj) FromJacobian(Q *G1Jac) *g1Proj {
	// memalloc
	var buf fp.Element
	buf.Square(&Q.Z)

	p.x.Mul(&Q.X, &Q.Z)
	p.y.Set(&Q.Y)
	p.z.Mul(&Q.Z, &buf)

	return p
}

// BatchJacobianToAffineG1Affine converts points in Jacobian coordinates to Affine coordinates
// performing a single field inversion (Montgomery batch inversion trick)
// result must be allocated with len(result) == len(points)
func BatchJacobianToAffineG1Affine(points []G1Jac, result []G1Affine) {
	zeroes := make([]bool, len(points))
	accumulator := fp.One()

	// batch invert all points[].Z coordinates with Montgomery batch inversion trick
	// (stores points[].Z^-1 in result[i].X to avoid allocating a slice of fr.Elements)
	for i := 0; i < len(points); i++ {
		if points[i].Z.IsZero() {
			zeroes[i] = true
			continue
		}
		result[i].X = accumulator
		accumulator.Mul(&accumulator, &points[i].Z)
	}

	var accInverse fp.Element
	accInverse.Inverse(&accumulator)

	for i := len(points) - 1; i >= 0; i-- {
		if zeroes[i] {
			// do nothing, X and Y are zeroes in affine.
			continue
		}
		result[i].X.Mul(&result[i].X, &accInverse)
		accInverse.Mul(&accInverse, &points[i].Z)
	}

	// batch convert to affine.
	parallel.Execute(len(points), func(start, end int) {
		for i := start; i < end; i++ {
			if zeroes[i] {
				// do nothing, X and Y are zeroes in affine.
				continue
			}
			var a, b fp.Element
			a = result[i].X
			b.Square(&a)
			result[i].X.Mul(&points[i].X, &b)
			result[i].Y.Mul(&points[i].Y, &b).
				Mul(&result[i].Y, &a)
		}
	})

}

// BatchScalarMultiplicationG1 multiplies the same base (generator) by all scalars
// and return resulting points in affine coordinates
// uses a simple windowed-NAF like exponentiation algorithm
func BatchScalarMultiplicationG1(base *G1Affine, scalars []fr.Element) []G1Affine {

	// approximate cost in group ops is
	// cost = 2^{c-1} + n(scalar.nbBits+nbChunks)

	nbPoints := uint64(len(scalars))
	min := ^uint64(0)
	bestC := 0
	for c := 2; c < 18; c++ {
		cost := uint64(1 << (c - 1))
		nbChunks := uint64(fr.Limbs * 64 / c)
		if (fr.Limbs*64)%c != 0 {
			nbChunks++
		}
		cost += nbPoints * ((fr.Limbs * 64) + nbChunks)
		if cost < min {
			min = cost
			bestC = c
		}
	}
	c := uint64(bestC) // window size
	nbChunks := int(fr.Limbs * 64 / c)
	if (fr.Limbs*64)%c != 0 {
		nbChunks++
	}
	mask := uint64((1 << c) - 1) // low c bits are 1
	msbWindow := uint64(1 << (c - 1))

	// precompute all powers of base for our window
	// note here that if performance is critical, we can implement as in the msmX methods
	// this allocation to be on the stack
	baseTable := make([]G1Jac, (1 << (c - 1)))
	baseTable[0].Set(&g1Infinity)
	baseTable[0].AddMixed(base)
	for i := 1; i < len(baseTable); i++ {
		baseTable[i] = baseTable[i-1]
		baseTable[i].AddMixed(base)
	}

	pScalars := partitionScalars(scalars, c)

	// compute offset and word selector / shift to select the right bits of our windows
	selectors := make([]selector, nbChunks)
	for chunk := 0; chunk < nbChunks; chunk++ {
		jc := uint64(uint64(chunk) * c)
		d := selector{}
		d.index = jc / 64
		d.shift = jc - (d.index * 64)
		d.mask = mask << d.shift
		d.multiWordSelect = (64%c) != 0 && d.shift > (64-c) && d.index < (fr.Limbs-1)
		if d.multiWordSelect {
			nbBitsHigh := d.shift - uint64(64-c)
			d.maskHigh = (1 << nbBitsHigh) - 1
			d.shiftHigh = (c - nbBitsHigh)
		}
		selectors[chunk] = d
	}

	// convert our base exp table into affine to use AddMixed
	baseTableAff := make([]G1Affine, (1 << (c - 1)))
	BatchJacobianToAffineG1Affine(baseTable, baseTableAff)
	toReturn := make([]G1Jac, len(scalars))

	// for each digit, take value in the base table, double it c time, voila.
	parallel.Execute(len(pScalars), func(start, end int) {
		var p G1Jac
		for i := start; i < end; i++ {
			p.Set(&g1Infinity)
			for chunk := nbChunks - 1; chunk >= 0; chunk-- {
				s := selectors[chunk]
				if chunk != nbChunks-1 {
					for j := uint64(0); j < c; j++ {
						p.DoubleAssign()
					}
				}

				bits := (pScalars[i][s.index] & s.mask) >> s.shift
				if s.multiWordSelect {
					bits += (pScalars[i][s.index+1] & s.maskHigh) << s.shiftHigh
				}

				if bits == 0 {
					continue
				}

				// if msbWindow bit is set, we need to substract
				if bits&msbWindow == 0 {
					// add

					p.AddMixed(&baseTableAff[bits-1])

				} else {
					// sub

					t := baseTableAff[bits & ^msbWindow]
					t.Neg(&t)
					p.AddMixed(&t)

				}
			}

			// set our result point

			toReturn[i] = p

		}
	})

	toReturnAff := make([]G1Affine, len(scalars))
	BatchJacobianToAffineG1Affine(toReturn, toReturnAff)
	return toReturnAff

}

// SizeOfG1AffineCompressed represents the size in bytes that a G1Affine need in binary form, compressed
const SizeOfG1AffineCompressed = 32

// SizeOfG1AffineUncompressed represents the size in bytes that a G1Affine need in binary form, uncompressed
const SizeOfG1AffineUncompressed = SizeOfG1AffineCompressed * 2

// Marshal converts p to a byte slice (without point compression)
func (p *G1Affine) Marshal() []byte {
	b := p.RawBytes()
	return b[:]
}

// Unmarshal is an allias to SetBytes()
func (p *G1Affine) Unmarshal(buf []byte) error {
	_, err := p.SetBytes(buf)
	return err
}

// Bytes returns binary representation of p
// will store X coordinate in regular form and a parity bit
// as we have less than 3 bits available in our coordinate, we can't follow BLS381 style encoding (ZCash/IETF)
// we use the 2 most significant bits instead
// 00 -> uncompressed
// 10 -> compressed, use smallest lexicographically square root of Y^2
// 11 -> compressed, use largest lexicographically square root of Y^2
// 01 -> compressed infinity point
// the "uncompressed infinity point" will just have 00 (uncompressed) followed by zeroes (infinity = 0,0 in affine coordinates)
func (p *G1Affine) Bytes() (res [SizeOfG1AffineCompressed]byte) {

	// check if p is infinity point
	if p.X.IsZero() && p.Y.IsZero() {
		res[0] = mCompressedInfinity
		return
	}

	// tmp is used to convert from montgomery representation to regular
	var tmp fp.Element

	msbMask := mCompressedSmallest
	// compressed, we need to know if Y is lexicographically bigger than -Y
	// if p.Y ">" -p.Y
	if p.Y.LexicographicallyLargest() {
		msbMask = mCompressedLargest
	}

	// we store X  and mask the most significant word with our metadata mask
	tmp = p.X
	tmp.FromMont()
	binary.BigEndian.PutUint64(res[24:32], tmp[0])
	binary.BigEndian.PutUint64(res[16:24], tmp[1])
	binary.BigEndian.PutUint64(res[8:16], tmp[2])
	binary.BigEndian.PutUint64(res[0:8], tmp[3])

	res[0] |= msbMask

	return
}

// RawBytes returns binary representation of p (stores X and Y coordinate)
// see Bytes() for a compressed representation
func (p *G1Affine) RawBytes() (res [SizeOfG1AffineUncompressed]byte) {

	// check if p is infinity point
	if p.X.IsZero() && p.Y.IsZero() {

		res[0] = mUncompressed

		return
	}

	// tmp is used to convert from montgomery representation to regular
	var tmp fp.Element

	// not compressed
	// we store the Y coordinate
	tmp = p.Y
	tmp.FromMont()
	binary.BigEndian.PutUint64(res[56:64], tmp[0])
	binary.BigEndian.PutUint64(res[48:56], tmp[1])
	binary.BigEndian.PutUint64(res[40:48], tmp[2])
	binary.BigEndian.PutUint64(res[32:40], tmp[3])

	// we store X  and mask the most significant word with our metadata mask
	tmp = p.X
	tmp.FromMont()
	binary.BigEndian.PutUint64(res[24:32], tmp[0])
	binary.BigEndian.PutUint64(res[16:24], tmp[1])
	binary.BigEndian.PutUint64(res[8:16], tmp[2])
	binary.BigEndian.PutUint64(res[0:8], tmp[3])

	res[0] |= mUncompressed

	return
}

// SetBytes sets p from binary representation in buf and returns number of consumed bytes
// bytes in buf must match either RawBytes() or Bytes() output
// if buf is too short io.ErrShortBuffer is returned
// if buf contains compressed representation (output from Bytes()) and we're unable to compute
// the Y coordinate (i.e the square root doesn't exist) this function retunrs an error
// note that this doesn't check if the resulting point is on the curve or in the correct subgroup
func (p *G1Affine) SetBytes(buf []byte) (int, error) {
	if len(buf) < SizeOfG1AffineCompressed {
		return 0, io.ErrShortBuffer
	}

	// most significant byte
	mData := buf[0] & mMask

	// check buffer size
	if mData == mUncompressed {
		if len(buf) < SizeOfG1AffineUncompressed {
			return 0, io.ErrShortBuffer
		}
	}

	// if infinity is encoded in the metadata, we don't need to read the buffer
	if mData == mCompressedInfinity {
		p.X.SetZero()
		p.Y.SetZero()
		return SizeOfG1AffineCompressed, nil
	}

	// TODO that's not elegant as it modifies buf; buf is now consumable only in 1 go routine
	buf[0] &= ^mMask

	// read X coordinate
	p.X.SetBytes(buf[0 : 0+fp.Bytes])

	// restore buf
	buf[0] |= mData

	// uncompressed point
	if mData == mUncompressed {
		// read Y coordinate
		p.Y.SetBytes(buf[32 : 32+fp.Bytes])

		return SizeOfG1AffineUncompressed, nil
	}

	// we have a compressed coordinate, we need to solve the curve equation to compute Y
	var YSquared, Y fp.Element

	YSquared.Square(&p.X).Mul(&YSquared, &p.X)
	YSquared.Add(&YSquared, &bCurveCoeff)
	if Y.Sqrt(&YSquared) == nil {
		return 0, errors.New("invalid compressed coordinate: square root doesn't exist")
	}

	if Y.LexicographicallyLargest() {
		// Y ">" -Y
		if mData == mCompressedSmallest {
			Y.Neg(&Y)
		}
	} else {
		// Y "<=" -Y
		if mData == mCompressedLargest {
			Y.Neg(&Y)
		}
	}

	p.Y = Y

	return SizeOfG1AffineCompressed, nil
}

// unsafeComputeY called by Decoder when processing slices of compressed point in parallel (step 2)
// it computes the Y coordinate from the already set X coordinate and is compute intensive
func (p *G1Affine) unsafeComputeY() error {
	// stored in unsafeSetCompressedBytes

	mData := byte(p.Y[0])

	// we have a compressed coordinate, we need to solve the curve equation to compute Y
	var YSquared, Y fp.Element

	YSquared.Square(&p.X).Mul(&YSquared, &p.X)
	YSquared.Add(&YSquared, &bCurveCoeff)
	if Y.Sqrt(&YSquared) == nil {
		return errors.New("invalid compressed coordinate: square root doesn't exist")
	}

	if Y.LexicographicallyLargest() {
		// Y ">" -Y
		if mData == mCompressedSmallest {
			Y.Neg(&Y)
		}
	} else {
		// Y "<=" -Y
		if mData == mCompressedLargest {
			Y.Neg(&Y)
		}
	}

	p.Y = Y

	return nil
}

// unsafeSetCompressedBytes is called by Decoder when processing slices of compressed point in parallel (step 1)
// assumes buf[:8] mask is set to compressed
// returns true if point is infinity and need no further processing
// it sets X coordinate and uses Y for scratch space to store decompression metadata
func (p *G1Affine) unsafeSetCompressedBytes(buf []byte) (isInfinity bool) {

	// read the most significant byte
	mData := buf[0] & mMask

	if mData == mCompressedInfinity {
		p.X.SetZero()
		p.Y.SetZero()
		isInfinity = true
		return
	}

	// read X

	// TODO that's not elegant as it modifies buf; buf is now consumable only in 1 go routine
	buf[0] &= ^mMask

	// read X coordinate
	p.X.SetBytes(buf[0 : 0+fp.Bytes])

	// restore buf
	buf[0] |= mData

	// store mData in p.Y[0]
	p.Y[0] = uint64(mData)

	// recomputing Y will be done asynchronously
	return
}
